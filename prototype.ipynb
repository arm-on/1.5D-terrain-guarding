{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prototype.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNpx1B2U3EIln/ZHm3IyiIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arm-on/1.5D-terrain-guarding/blob/master/prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRYVm9y1eAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxZH0CrXWAlN",
        "colab_type": "text"
      },
      "source": [
        "**Authentication**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7fiSgckBIpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2403d82a-9191-4ab7-e7dc-a13c4438124f"
      },
      "source": [
        "drive.mount('/gdrive', force_remount=True)\n",
        "%cd /gdrive/My Drive/THESIS/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/THESIS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMzxZkFjWHca",
        "colab_type": "text"
      },
      "source": [
        "**Importing the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ224cPaBO8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from experiment_v8 import *\n",
        "from globals import *\n",
        "from attention import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lup1Ja_WcPF",
        "colab_type": "text"
      },
      "source": [
        "**Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLytgx5NCDvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "experiment_phase = 'training' # phase: training/querying/continue\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "random_seed = 1234\n",
        "tf.random.set_seed(random_seed)\n",
        "seed(random_seed)\n",
        "shared_files = read_csv_as_dict('shared_files.csv')\n",
        "globals().update(shared_files)\n",
        "project_path = 'June/EXP-2020-6-20/'\n",
        "folder_path = 'wordexp/'\n",
        "gloss_max_rank = 100000\n",
        "num_head_words = 3000\n",
        "input_emb_size = 300\n",
        "lstm_output_size = 300\n",
        "dense_output_size = 300\n",
        "output_emb_size = 300\n",
        "pretrained_input = True\n",
        "fixed_embeddings = False\n",
        "pretrained_target = True\n",
        "normalize_vectors = False\n",
        "add_context = False\n",
        "augment_head = False\n",
        "augment_gloss = False\n",
        "save_train_test_samples = False\n",
        "save_tools = False\n",
        "save_weights = True\n",
        "use_intent_classifier = False\n",
        "max_hfake_per_sample = 5\n",
        "gfake_per_sample = {\n",
        "    3:5,\n",
        "    4:5\n",
        "}\n",
        "context_max_rank = 100000\n",
        "max_seq_len = 20\n",
        "learning_rate = 1.0\n",
        "margin = 1.0\n",
        "num_epochs = 50\n",
        "batch_size = 16\n",
        "test_sample_size = 40\n",
        "test_sample_topn = 10\n",
        "input_vector_model = 'fasttext'\n",
        "output_vector_model = 'fasttext'\n",
        "data_sources = {'wikipedia','amid','dehkhoda-vy','moeen-vy','farsnet'}\n",
        "vector_model_dir = {'fasttext':fasttext_dict_dir,'irblog':irblog2_wv_dir,'wiki200':wiki_wv_200_dir,'hamwv':hamshahri_wv_dir,'hamft':hamshahri_ft_dir,'wordak':wordak_wv_dir, 'wiki300':wiki_wv_300_dir,'twitter':twitter_wv_dir}\n",
        "max_sense = {\n",
        "    'wikipedia':500,\n",
        "    'amid':500,\n",
        "    'dehkhoda-vy':500,\n",
        "    'moeen-vy':500,\n",
        "    'farsnet':500\n",
        "}\n",
        "model_architecture = 'BiLSTM (attention)' #  bag of words, LSTM, BiLSTM, LSTM (attention), BiLSTM (attention), BiLSTM (multiheadattention)\n",
        "num_heads = 8\n",
        "d_model = 300\n",
        "loss_function = 'cosine' # cosine, ranking\n",
        "intent_project_path = 'July/2020-7-23/'\n",
        "intent_folder_path = 'exp9/'\n",
        "intent_maxlen = 20\n",
        "intent_threshold = 0.3\n",
        "intent_coefficient = 0.4\n",
        "vec_sim_coefficient = 0.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSYzfzFTHopD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase == 'training':\n",
        "    log_dir = project_path+folder_path+'report.dat'\n",
        "    log_obj = {\n",
        "        'gloss':str(gloss_max_rank),\n",
        "        'head':str(num_head_words),\n",
        "        'input_emb':str(input_emb_size),\n",
        "        'output_emb':str(output_emb_size),\n",
        "        'dense_output':str(dense_output_size),\n",
        "        'lstm_output':str(lstm_output_size),\n",
        "        'pretrained_input':input_vector_model if pretrained_input else 'no',\n",
        "        'pretrained_target':output_vector_model if pretrained_target else 'no',\n",
        "        'fixed_embeddings':'yes' if fixed_embeddings else 'no',\n",
        "        'normalize_vectors':'yes' if normalize_vectors else 'no',\n",
        "        'intent_classifier':'yes' if use_intent_classifier else 'no',\n",
        "        'context':str(context_max_rank) if add_context else 'no',\n",
        "        'augment_head':str(max_hfake_per_sample) if augment_head else 'no',\n",
        "        'augment_gloss':str(gfake_per_sample) if augment_gloss else 'no',\n",
        "        'margin':str(margin),\n",
        "        'seq_len':str(max_seq_len),\n",
        "        'learning_rate':str(learning_rate),\n",
        "        'batch_size':str(batch_size),\n",
        "        'data_sources':\" \".join(data_sources),\n",
        "        'max_sense':str(max_sense),\n",
        "        'model_architecture':model_architecture,\n",
        "        'loss_function':loss_function,\n",
        "        'intent_path':intent_project_path+intent_folder_path,\n",
        "        'intent_maxlen':str(intent_maxlen),\n",
        "        'intent_threshold':str(intent_threshold),\n",
        "        'intent_coefficient':str(intent_coefficient),\n",
        "        'vec_sim_coefficient':str(vec_sim_coefficient)\n",
        "    }\n",
        "    init_log(log_obj, log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dhnb4tXWtDP",
        "colab_type": "text"
      },
      "source": [
        "**Loading**<br/>\n",
        "* Data \n",
        "* Stopwords\n",
        "* Normalizer\n",
        "* Ranking of words by frequency\n",
        "* Synonyms Set\n",
        "* POS Tags\n",
        "* Vector Model(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fc3W5BaNM4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_tags = read_pickle(wordtags_dir) if use_intent_classifier else defaultdict(set)\n",
        "ranking = read_pickle(ranking_dir)\n",
        "all_words = set(ranking)\n",
        "stopwords = read_lines(stopwords_dir)\n",
        "normalizer = read_json(normalizer_dir)\n",
        "synonyms = read_pickle(synonyms_dir)\n",
        "if experiment_phase in {'training','continue'}:\n",
        "    data = read_pickle(data_dir)\n",
        "input_vec_model = read_pickle(vector_model_dir[input_vector_model])\n",
        "output_vec_model = read_pickle(vector_model_dir[input_vector_model])\n",
        "if use_intent_classifier == True:\n",
        "    with open(intent_project_path+intent_folder_path+'model.json','r') as json_file:\n",
        "        intent_model_arch = json_file.read()\n",
        "    intent_model = tf.keras.models.model_from_json(intent_model_arch)\n",
        "    intent_model.load_weights(intent_project_path+intent_folder_path+'weights.h5')\n",
        "    intent_id2c = read_pickle(intent_project_path+intent_folder_path+'id2c.pkl')\n",
        "    intent_g2id = read_pickle(intent_project_path+intent_folder_path+'intent-g2id.pkl')\n",
        "    tools = {'normalizer':normalizer,'stopwords':stopwords,'synonyms':synonyms,'word_tags':word_tags, 'intent_g2id':intent_g2id, 'intent_maxlen':intent_maxlen, 'intent_model':intent_model, 'intent_threshold':intent_threshold, 'intent_id2c':intent_id2c, 'intent_coefficient':intent_coefficient, 'vec_sim_coefficient':vec_sim_coefficient}\n",
        "else:\n",
        "    tools = {'normalizer':normalizer,'stopwords':stopwords,'synonyms':synonyms,'word_tags':word_tags}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB24i9DjCopu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "items = []\n",
        "sources_counter = Counter()\n",
        "word_rank = {word:idx+1 for idx, word in enumerate(ranking)}\n",
        "if experiment_phase in {'training','continue'}:\n",
        "    for item in data:\n",
        "        sources_counter[item['dic']] += 1\n",
        "        new_item = {'word':item['word'],\n",
        "                    'rank':word_rank[item['word']]+1 if item['word'] in all_words else len(ranking)+1,\n",
        "                    'original_definition':item['meaning'],\n",
        "                    'preprocessed_definition':item['meaning'],\n",
        "                    'active':True,\n",
        "                    'array':None,\n",
        "                    'context':False,\n",
        "                    'type':'main',\n",
        "                    'sense_tags':item['tags'] if 'tags' in item else set(),\n",
        "                    'general_tags':item['general_tags'] if 'general_tags' in item else set(),\n",
        "                    'sid':item['sense_id'],\n",
        "                    'source':item['dic'],\n",
        "                    'phase':item['phase']\n",
        "                    }\n",
        "        items.append(new_item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VzY8W9_XFQh",
        "colab_type": "text"
      },
      "source": [
        "**Preparing the Train, Test and Dev Sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B01R_HZH8WKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    ## fixing the data sources and senses\n",
        "    for item in items:\n",
        "        if item['source'] not in data_sources or (item['sid']>max_sense[item['source']]):\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    ## removing html tags\n",
        "    for item in items:\n",
        "        item['word'] = remove_html_tags(item['word'])\n",
        "        item['original_definition'] = remove_html_tags(item['original_definition'])\n",
        "        item['preprocessed_definition'] = remove_html_tags(item['preprocessed_definition'])\n",
        "    ## deactivating samples without any Persian information\n",
        "    for item in items:\n",
        "        if not (has_any_persian(item['word']) and has_any_persian(item['original_definition'])):\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    log_str = 'with Persian information - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## normalizing characters\n",
        "    for item in items:\n",
        "        item['preprocessed_definition'] = normalize_characters(item['preprocessed_definition'], normalizer)\n",
        "        item['word'] = normalize_characters(item['word'], normalizer)\n",
        "    ## correcting whitespaces\n",
        "    for item in items:\n",
        "        item['word'] = correct_whitespaces(item['word'])\n",
        "        item['preprocessed_definition'] = correct_whitespaces(item['preprocessed_definition'])\n",
        "    ## tokenization\n",
        "    for item in items:\n",
        "        item['preprocessed_definition'] = tokenize(item['preprocessed_definition'])\n",
        "    ## removing self-definition(s)\n",
        "    for item in items:\n",
        "        item['preprocessed_definition'] = remove_self_definition(item['preprocessed_definition'], item['word'])\n",
        "    ## removing stopwords\n",
        "    for item in items:\n",
        "        item['preprocessed_definition'] = remove_stopwords(item['preprocessed_definition'], stopwords)\n",
        "    for item in items:\n",
        "        if item['word'] in stopwords:\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    log_str = 'Stopwords removed - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## deactivating unlearnables\n",
        "    for item in items:\n",
        "        if not has_vector(item['word'], output_vec_model):\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    log_str = 'Unlearnables Removed - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## deactivating short words\n",
        "    for item in items:\n",
        "        if len(item['word']) < 3:\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    log_str = 'Short words removed - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## deactivating short definitions\n",
        "    for item in items:\n",
        "        if len(item['preprocessed_definition']) == 1 and len(item['preprocessed_definition'][0]) < 3:\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    log_str = 'Short definitions removed - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## deactivating meaningless words\n",
        "    for item in items:\n",
        "        if len(item['preprocessed_definition']) == 0:\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    log_str = 'Meaningless words removed - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## normalizing heads by ranking (frequency)\n",
        "    active_words = set([item['word'] for item in items if item['active']==True])\n",
        "    temp_ranking = [word for word in ranking if word in active_words]\n",
        "    frequent_words = set([word for word in temp_ranking][:num_head_words])\n",
        "    context_words = set([word for word in temp_ranking][:context_max_rank])\n",
        "    for item in items:\n",
        "        if item['word'] not in frequent_words:\n",
        "            if add_context == True:\n",
        "                if item['word'] in context_words:\n",
        "                    item['phase'] = 'train'\n",
        "                    item['context'] = True\n",
        "                else:\n",
        "                    item['active'] = False\n",
        "            else:\n",
        "                item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    main_words = set([item['word'] for item in items if item['context']==False])\n",
        "    log_str = 'Normalized heads by frequency - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words)) +' ('+str(len(main_words))+' Main Words)'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## generating the comparison matrix\n",
        "    h2id = {}\n",
        "    id2h = {}\n",
        "    for i, h in enumerate(frequent_words):\n",
        "        h2id[h] = i\n",
        "        id2h[i] = h\n",
        "    comparison_matrix = zeros((num_head_words, output_emb_size))\n",
        "    if pretrained_target == True:\n",
        "        for item in items:\n",
        "            if item['phase'] == 'train' and item['word'] in frequent_words:\n",
        "                comparison_matrix[h2id[item['word']]] = output_vec_model[item['word']]\n",
        "    ## normalizing the tokens based on their frequency\n",
        "    tokens_lst = []\n",
        "    for item in items:\n",
        "        if item['phase'] == 'train':\n",
        "            tokens_lst.extend(item['preprocessed_definition'])\n",
        "    frequent_tokens = most_frequent(tokens_lst, gloss_max_rank)\n",
        "    for item in items:\n",
        "        item['preprocessed_definition'] = [token if token in frequent_tokens else 'UNK' for token in item['preprocessed_definition']]\n",
        "        if 'UNK' in item['preprocessed_definition']:\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    main_words = set([item['word'] for item in items if item['context']==False])\n",
        "    log_str = 'Normalized tokens by frequency - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words)) +' ('+str(len(main_words))+' Main Words)'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## encoding the tokens\n",
        "    t2id = {}\n",
        "    id2t = {}\n",
        "    t2id['PAD'] = 0\n",
        "    t2id['UNK'] = 1\n",
        "    id2t[0] = 'PAD'\n",
        "    id2t[1] = 'UNK' \n",
        "    for i, t in enumerate(frequent_tokens, start=2):\n",
        "        t2id[t] = i\n",
        "        id2t[i] = t\n",
        "    ## generating the embedding matrix\n",
        "    embedding_matrix = zeros((len(frequent_tokens)+2, input_emb_size))\n",
        "    if pretrained_input == True:\n",
        "        for token in frequent_tokens:\n",
        "            try:\n",
        "                embedding_matrix[t2id[token]] = input_vec_model[token]\n",
        "                if normalize_vectors == True and LA.norm(embedding_matrix[t2id[token]])>0.0:\n",
        "                    embedding_matrix[t2id[token]] = embedding_matrix[t2id[token]]/LA.norm(embedding_matrix[t2id[token]])\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    ## fixing the length of sequences\n",
        "    for item in items:\n",
        "        tokens = item['preprocessed_definition']\n",
        "        item['preprocessed_definition'] = tokens[:max_seq_len] if len(tokens)>=max_seq_len else tokens+['PAD' for j in range(max_seq_len-len(tokens))]\n",
        "    ## removing the words with definitions that are only consisted of 'PAD' and 'UNK'\n",
        "    for item in items:\n",
        "        tokens = item['preprocessed_definition']\n",
        "        tokens = set(tokens)\n",
        "        if tokens.issubset({'PAD','UNK'}):\n",
        "            item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    log_str = 'Infoless definitions (UNK and PAD) removed - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "\n",
        "    ## removing duplicates (samples with equal word and definition)\n",
        "    # from the training data\n",
        "    sample_count = Counter()\n",
        "    for item in items:\n",
        "        if item['phase'] == 'train':\n",
        "            word = item['word']\n",
        "            tokens = item['preprocessed_definition']\n",
        "            sample_key = word+'-'+\"-\".join(tokens)\n",
        "            sample_count[sample_key] += 1\n",
        "            if sample_count[sample_key] > 1:\n",
        "                item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    main_words = set([item['word'] for item in items if item['context']==False])\n",
        "    log_str = 'duplicates removed from training data - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))+' ('+str(len(main_words))+' Main Words)'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    # from the testing and development data\n",
        "    for item in items:\n",
        "        if item['phase'] != 'train':\n",
        "            word = item['word']\n",
        "            tokens = item['preprocessed_definition']\n",
        "            sample_key = word+'-'+\"-\".join(tokens)\n",
        "            sample_count[sample_key] += 1\n",
        "            if sample_count[sample_key] > 1:\n",
        "                item['active'] = False\n",
        "    items = [item for item in items if item['active'] == True]\n",
        "    all_words = set([item['word'] for item in items])\n",
        "    main_words = set([item['word'] for item in items if item['context']==False])\n",
        "    log_str = 'duplicates removed from unseen data - Number of Samples: '+str(len(items))+' - Number of Words: '+str(len(all_words))+' ('+str(len(main_words))+' Main Words)'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    ## generating the data\n",
        "    for item in items:\n",
        "        tokens = item['preprocessed_definition']\n",
        "        nparray = [t2id[token] for token in tokens]\n",
        "        nparray = array(nparray)\n",
        "        item['array'] = nparray\n",
        "    train = [item for item in items if item['phase'] == 'train']\n",
        "    test = [item for item in items if item['phase'] == 'test']\n",
        "    dev = [item for item in items if item['phase'] == 'dev']\n",
        "    log_str = 'After Preprocessing: '+str(len(train))+' training samples, '+str(len(test))+' testing samples and '+str(len(dev))+' samples for development'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    tools_part2 = {'t2id':t2id,'id2t':id2t,'h2id':h2id,'id2h':id2h,'embedding_matrix':embedding_matrix,'comparison_matrix':comparison_matrix}\n",
        "    tools.update(tools_part2)\n",
        "    train_sources_counter = Counter()\n",
        "    for item in train:\n",
        "        train_sources_counter[item['source']] += 1\n",
        "    test_sources_counter = Counter()\n",
        "    for item in test:\n",
        "        test_sources_counter[item['source']] += 1\n",
        "    dev_sources_counter = Counter()\n",
        "    for item in dev:\n",
        "        dev_sources_counter[item['source']] += 1\n",
        "    write_line_to_file('Training Data: '+str(sum(train_sources_counter.values())), log_dir)\n",
        "    write_line_to_file(str(train_sources_counter), log_dir)\n",
        "    write_line_to_file('Development Data: '+str(sum(dev_sources_counter.values())), log_dir)\n",
        "    write_line_to_file(str(dev_sources_counter), log_dir)\n",
        "    write_line_to_file('Testing Data: '+str(sum(test_sources_counter.values())), log_dir)\n",
        "    write_line_to_file(str(test_sources_counter), log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOsqxIYlGMZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase == 'training':\n",
        "    words = list(set(list(h2id.keys())))\n",
        "    with open(project_path+folder_path+'words'+str(num_head_words)+'.pkl','wb') as file:\n",
        "        pickle.dump(words, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRtgkwzAWtGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    from copy import deepcopy\n",
        "    # Making a counter to see if a sample already exists\n",
        "    item_count = Counter()\n",
        "    for item in items:\n",
        "        word = item['word']\n",
        "        tokens = item['preprocessed_definition']\n",
        "        definition = \" \".join(tokens)\n",
        "        key = word+'-'+definition\n",
        "        item_count[key] += 1\n",
        "\n",
        "    # Augmenting (head words)\n",
        "\n",
        "    head_augment = []\n",
        "    all_heads = set([item['word'] for item in items if item['phase']=='train'])\n",
        "    replaceable_heads = set([word for word in all_heads if word in synonyms])\n",
        "    if augment_head == True:\n",
        "        for item in train:\n",
        "            if len(train) % 100000 == 0:\n",
        "                print(len(train))\n",
        "            word = item['word']\n",
        "            tokens = item['preprocessed_definition']\n",
        "            definition = \" \".join(tokens)\n",
        "            syn_words = synonyms[word]\n",
        "            syn_words = set([w for w in syn_words if w in output_vec_model and w != word])\n",
        "            if len(syn_words) == 0:\n",
        "                continue\n",
        "            if len(syn_words) >= max_hfake_per_sample:\n",
        "                syn_candidates = sample(syn_words, max_hfake_per_sample)\n",
        "            else:\n",
        "                syn_candidates = list(syn_words)\n",
        "            for candidate in syn_candidates:\n",
        "                new_item = item.copy()\n",
        "                new_item['word'] = candidate\n",
        "                new_item['type'] = 'augment'\n",
        "                key = candidate+'-'+definition\n",
        "                if item_count[key] == 0:\n",
        "                    head_augment.append(new_item)\n",
        "                    item_count[key] += 1\n",
        "\n",
        "    # Augmenting (gloss words)\n",
        "\n",
        "    gloss_augment = []\n",
        "\n",
        "\n",
        "    usable_synonyms = defaultdict()\n",
        "    for (word, synset) in synonyms.items():\n",
        "        temp_synset = set([syn for syn in synset if syn != word and syn in t2id])\n",
        "        if len(temp_synset) > 0:\n",
        "            usable_synonyms[word] = temp_synset\n",
        "\n",
        "    gloss_augment = []\n",
        "\n",
        "    if augment_gloss == True:\n",
        "        for item in train:\n",
        "            \n",
        "            if item['type'] != 'main':\n",
        "                continue\n",
        "            word = item['word']\n",
        "            tokens = item['preprocessed_definition']\n",
        "            definition = \" \".join(tokens)\n",
        "            rep_tokens = set([token for token in tokens if token in usable_synonyms and token in input_vec_model])\n",
        "            for num_tokens_to_replace in gfake_per_sample.keys():\n",
        "                if len(rep_tokens) < num_tokens_to_replace:\n",
        "                    continue\n",
        "                remaining_samples = gfake_per_sample[num_tokens_to_replace]\n",
        "                remaining_tries = 50\n",
        "                while remaining_samples > 0 and remaining_tries > 0:\n",
        "                    chosen_to_be_changed = set(sample(rep_tokens, num_tokens_to_replace))\n",
        "                    what_to_replace_with = defaultdict()\n",
        "                    for token in chosen_to_be_changed:\n",
        "                        candidates = usable_synonyms[token]\n",
        "                        what_to_replace_with[token] = sample(candidates, 1)[0]\n",
        "                    new_item = deepcopy(item)\n",
        "                    new_item['preprocessed_definition'] = [what_to_replace_with[t] if t in chosen_to_be_changed else t for t in new_item['preprocessed_definition']]\n",
        "                    new_item['array'] = np.array([t2id[t] for t in new_item['preprocessed_definition']])\n",
        "                    new_item_key = new_item['word'] + '-' + \" \".join(new_item['preprocessed_definition'])\n",
        "                    remaining_tries -= 1\n",
        "                    if item_count[new_item_key] == 0:\n",
        "                        gloss_augment.append(new_item)\n",
        "                        item_count[new_item_key] += 1\n",
        "                        remaining_samples -= 1\n",
        "\n",
        "\n",
        "    train.extend(head_augment)\n",
        "    del head_augment\n",
        "    log_str = 'finished augmentation (head) - '+str(len(train))+' samples'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    train.extend(gloss_augment)\n",
        "    del gloss_augment\n",
        "    log_str = 'finished augmentation (gloss) - '+str(len(train))+' samples'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    del items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDRxe3_DeGMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase == 'training' and save_train_test_samples == True:\n",
        "    train_data = defaultdict(list)\n",
        "    test_data = defaultdict(list)\n",
        "    train_original_data = defaultdict(list)\n",
        "    test_original_data = defaultdict(list)\n",
        "    for item in train:\n",
        "        word = item['word']\n",
        "        original_definition = \" \".join(item['original_definition'].split()[:20])\n",
        "        definition = \" \".join([token for token in item['preprocessed_definition'] if not token == 'PAD'])\n",
        "        train_data[word].append(definition)\n",
        "        train_original_data[word].append(original_definition)\n",
        "    for item in test:\n",
        "        word = item['word']\n",
        "        original_definition = \" \".join(item['original_definition'].split()[:20])\n",
        "        definition = \" \".join([token for token in item['preprocessed_definition'] if not token == 'PAD'])\n",
        "        test_data[word].append(definition)\n",
        "        test_original_data[word].append(original_definition)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exyXpM20Sh7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    x_train = array([item['array'] for item in train])\n",
        "    y_train = array([comparison_matrix[h2id[item['word']]] if item['word'] in h2id else output_vec_model[item['word']] for item in train])\n",
        "    x_dev = array([item['array'] for item in dev])\n",
        "    y_dev = array([comparison_matrix[h2id[item['word']]] if item['word'] in h2id else output_vec_model[item['word']] for item in dev])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTHzcwVEXQ3k",
        "colab_type": "text"
      },
      "source": [
        "**Saving the necessary variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAMMkkIVXR6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase == 'training':\n",
        "    if save_tools == True:\n",
        "        with open(project_path+folder_path+'tools.pkl','wb') as file:\n",
        "            pickle.dump(tools, file)\n",
        "    if save_train_test_samples == True:\n",
        "        train_test_data = (train_data, train_original_data, test_data, test_original_data)\n",
        "        with open(project_path+folder_path+'train_test_data.pkl','wb') as file:\n",
        "            pickle.dump(train_test_data, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx7KX9xvKhPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase == 'training':\n",
        "    emb_matrix_shape = embedding_matrix.shape\n",
        "    additional_tools = {'comparison_matrix':comparison_matrix, 't2id':t2id, 'h2id':h2id, 'id2h':id2h}\n",
        "    query_tools = (emb_matrix_shape, additional_tools)\n",
        "    with open(project_path+folder_path+'query_tools.pkl','wb') as file:\n",
        "        pickle.dump(query_tools, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_gBuN56Ivew",
        "colab_type": "text"
      },
      "source": [
        "**Loading Necessary Tools for Querying**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWelxKZ2KJeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase == 'querying':\n",
        "    emb_matrix_shape , additional_tools = read_pickle(project_path+folder_path+'query_tools.pkl')\n",
        "    tools.update(additional_tools)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsWo-X61Xiku",
        "colab_type": "text"
      },
      "source": [
        "**Making a Model and Training it**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16aucIuAj_Gy",
        "colab_type": "text"
      },
      "source": [
        "*Bag of Words*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRZhlJhpiipI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if model_architecture == 'bag of words':\n",
        "    sequence_input = Input(shape=(max_seq_len,), dtype='int32', name='input')\n",
        "    embedding_layer = Embedding(emb_matrix_shape[0],\n",
        "                                input_emb_size,\n",
        "                                weights=[embedding_matrix] if 'embedding_matrix' in globals() else [np.zeros(emb_matrix_shape)],\n",
        "                                input_length=max_seq_len,\n",
        "                                trainable=not fixed_embeddings,\n",
        "                                mask_zero=True, name='embedding')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    mean_vector = Lambda(lambda x: mean(x, axis=1), name='lambda')(embedded_sequences)\n",
        "    mean_vector = Flatten(name='flatten')(mean_vector)\n",
        "    output = Dense(dense_output_size, activation='tanh', name='dense')(mean_vector)\n",
        "    adadelta = optimizers.Adadelta(lr=learning_rate)\n",
        "    model = Model(inputs=sequence_input, outputs=output)\n",
        "    if loss_function == 'cosine':\n",
        "        model.compile(loss=cosine_loss,\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])\n",
        "    elif loss_function == 'ranking':\n",
        "        model.compile(loss=rank_loss(margin),\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o1UORkqk6Ed",
        "colab_type": "text"
      },
      "source": [
        "*LSTM (without attention)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGT_QZftoYWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if model_architecture == 'LSTM':\n",
        "    sequence_input = Input(shape=(max_seq_len,), dtype='int32', name='input')\n",
        "    embedding_layer = Embedding(emb_matrix_shape[0],\n",
        "                                input_emb_size,\n",
        "                                weights=[embedding_matrix]  if 'embedding_matrix' in globals() else [np.zeros(emb_matrix_shape)],\n",
        "                                input_length=max_seq_len,\n",
        "                                trainable=not fixed_embeddings,\n",
        "                                mask_zero=True, name='embedding')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    lstm = LSTM(lstm_output_size, return_sequences=False, name='lstm')(embedded_sequences)\n",
        "    output = Dense(dense_output_size, activation='tanh', name='dense')(lstm)\n",
        "    adadelta = optimizers.Adadelta(lr=learning_rate)\n",
        "    model = Model(inputs=sequence_input, outputs=output)\n",
        "    if loss_function == 'cosine':\n",
        "        model.compile(loss=cosine_loss,\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])\n",
        "    elif loss_function == 'ranking':\n",
        "        model.compile(loss=rank_loss(margin),\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkWxjSIZlwAA",
        "colab_type": "text"
      },
      "source": [
        "*BiLSTM (without attention)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SWCnEdXlyU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if model_architecture == 'BiLSTM':\n",
        "    sequence_input = Input(shape=(max_seq_len,), dtype='int32', name='input')\n",
        "    embedding_layer = Embedding(emb_matrix_shape[0],\n",
        "                                input_emb_size,\n",
        "                                weights=[embedding_matrix] if 'embedding_matrix' in globals() else [np.zeros(emb_matrix_shape)],\n",
        "                                input_length=max_seq_len,\n",
        "                                trainable=not fixed_embeddings,\n",
        "                                mask_zero=True, name='embedding')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    lstm = Bidirectional(LSTM(lstm_output_size, return_sequences=False, name='lstm'))(embedded_sequences)\n",
        "    output = Dense(dense_output_size, activation='tanh', name='dense')(lstm)\n",
        "    adadelta = optimizers.Adadelta(lr=learning_rate)\n",
        "    model = Model(inputs=sequence_input, outputs=output)\n",
        "    if loss_function == 'cosine':\n",
        "        model.compile(loss=cosine_loss,\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])\n",
        "    elif loss_function == 'ranking':\n",
        "        model.compile(loss=rank_loss(margin),\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBxsYqtk1z6J",
        "colab_type": "text"
      },
      "source": [
        "*LSTM (with attention)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_kTQtT2Wkmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if model_architecture == 'LSTM (attention)':\n",
        "    sequence_input = Input(shape=(max_seq_len,), dtype='int32', name='input')\n",
        "    embedding_layer = Embedding(emb_matrix_shape[0],\n",
        "                                input_emb_size,\n",
        "                                weights=[embedding_matrix] if 'embedding_matrix' in globals() else [np.zeros(emb_matrix_shape)],\n",
        "                                input_length=max_seq_len,\n",
        "                                trainable=not fixed_embeddings,\n",
        "                                mask_zero=True, name='embedding')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    lstm, state_h, state_c = LSTM(lstm_output_size, return_sequences=True, return_state=True, name='lstm')(embedded_sequences)\n",
        "    state_h = Lambda(lambda x: tf.expand_dims(x, 1), name='expand_dims')(state_h)\n",
        "    state_h = Dense(300, name='d1')(state_h)\n",
        "    lstm = Dense(300, name='d2')(lstm)\n",
        "    weights, context_vector = AdditiveAttention(name='attention')([state_h, lstm])\n",
        "    weights = Lambda(lambda x: tf.squeeze(x), name='squeezed_weights')(weights)\n",
        "    output = Dense(dense_output_size, activation='tanh', name='dense')(context_vector)\n",
        "    output = Lambda(lambda x: tf.squeeze(x), name='squeezed_output')(output)\n",
        "    adadelta = optimizers.Adadelta(lr=learning_rate)\n",
        "    model = Model(inputs=sequence_input, outputs=output)\n",
        "    attention_model = Model(inputs=sequence_input, outputs=weights)\n",
        "    if loss_function == 'cosine':\n",
        "        model.compile(loss=cosine_loss,\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])\n",
        "    elif loss_function == 'ranking':\n",
        "        model.compile(loss=rank_loss(margin),\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqiOp6yVl_Fe",
        "colab_type": "text"
      },
      "source": [
        "*BiLSTM (with attention)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_CcCLEK0r8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if model_architecture == 'BiLSTM (attention)':\n",
        "    sequence_input = Input(shape=(max_seq_len,), dtype='int32', name='input')\n",
        "    embedding_layer = Embedding(emb_matrix_shape[0],\n",
        "                                input_emb_size,\n",
        "                                weights=[embedding_matrix] if 'embedding_matrix' in globals() else [np.zeros(emb_matrix_shape)],\n",
        "                                input_length=max_seq_len,\n",
        "                                trainable=not fixed_embeddings,\n",
        "                                mask_zero=True, name='embedding')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(lstm_output_size, return_sequences=True, return_state=True, name='lstm'))(embedded_sequences)\n",
        "    state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "    state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "    state_h = tf.expand_dims(state_h, 1)\n",
        "    state_h = Dense(300, name='d1')(state_h)\n",
        "    lstm = Dense(300, name='d2')(lstm)\n",
        "    weights, context_vector = AdditiveAttention()([state_h, lstm])\n",
        "    weights = tf.squeeze(weights)\n",
        "    output = Dense(dense_output_size, activation='tanh', name='dense')(context_vector)\n",
        "    output = tf.squeeze(output)\n",
        "    adadelta = optimizers.Adadelta(lr=learning_rate)\n",
        "    model = Model(inputs=sequence_input, outputs=output)\n",
        "    attention_model = Model(inputs=sequence_input, outputs=weights)\n",
        "    if loss_function == 'cosine':\n",
        "        model.compile(loss=cosine_loss,\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])\n",
        "    elif loss_function == 'ranking':\n",
        "        model.compile(loss=rank_loss(1.0),\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VUXgFCzbhTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lstm: [2, 20, 600]\n",
        "# state_h: [2, 600]\n",
        "# new_lstm (after Dense(300)):  [2, 20, 300]\n",
        "# new_state_h (after expand_dims): [2, 1, 600]\n",
        "# new_state_h (after Dense(300)): [2, 1, 300]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68oE-F-AQFw3",
        "colab_type": "text"
      },
      "source": [
        "*Multi-head Attention*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFDwQjGbSvs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if model_architecture == 'BiLSTM (multiheadattention)':\n",
        "    sequence_input = Input(shape=(max_seq_len,), dtype='int32', name='input')\n",
        "    embedding_layer = Embedding(emb_matrix_shape[0],\n",
        "                                input_emb_size,\n",
        "                                weights=[embedding_matrix] if 'embedding_matrix' in globals() else [np.zeros(emb_matrix_shape)],\n",
        "                                input_length=max_seq_len,\n",
        "                                trainable=not fixed_embeddings,\n",
        "                                mask_zero=True, name='embedding')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(lstm_output_size, return_sequences=True, return_state=True, name='lstm'))(embedded_sequences)\n",
        "    state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "    state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "    state_h = tf.expand_dims(state_h, 1)\n",
        "    context_vector = MultiheadAttention(num_heads, d_model)([state_h, lstm, lstm])\n",
        "    output = Dense(dense_output_size, activation='tanh', name='dense')(context_vector)\n",
        "    output = tf.squeeze(output)\n",
        "    adadelta = optimizers.Adadelta(lr=learning_rate)\n",
        "    model = Model(inputs=sequence_input, outputs=output)\n",
        "    if loss_function == 'cosine':\n",
        "        model.compile(loss=cosine_loss,\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])\n",
        "    elif loss_function == 'ranking':\n",
        "        model.compile(loss=rank_loss(1.0),\n",
        "                    optimizer=adadelta,metrics=[cosine_sim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XAA9tjEwT09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase == 'training':\n",
        "    with open(log_dir,'a+',encoding='utf-8') as file:\n",
        "        model.summary(print_fn=lambda line: file.write(line + '\\n'))\n",
        "    write_line_to_file(str(model.loss), log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtLV5GUxUsOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd9b128a-e97e-43eb-d7d9-4a0f1b1ce0bf"
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    json_logging_callback = LambdaCallback(on_epoch_end=lambda epoch, logs:e_end('cosine_sim', epoch, logs, project_path+folder_path+'report.dat'))\n",
        "    optimizer_weights_callback = LambdaCallback(on_epoch_end=save_optimizer_state(model, project_path+folder_path+'optimizer_weights.pkl'))\n",
        "    model_weights_checkpoint = ModelCheckpoint(project_path+folder_path+'weights.h5', monitor='val_loss', verbose=0,save_best_only=True, mode='min', period=1, save_weights_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True,patience=2, mode='min',min_delta=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWDiArvXU4sL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "63da54d3-38dc-4584-97d9-bab720c4f500"
      },
      "source": [
        "if experiment_phase == 'continue':\n",
        "    model.fit(x_train[:1000], y_train[:1000], epochs=1, batch_size=batch_size, validation_data=(x_dev, y_dev))\n",
        "    with open(project_path+folder_path+'optimizer_weights.pkl') as f:\n",
        "        optimizer_weights = pickle.load(f)\n",
        "    model.optimizer.set_weights(optimizer_weights)   \n",
        "    model.set_weights(project_path+folder_path+'weights.h5')\n",
        "    start = time()\n",
        "    history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(x_dev, y_dev)\n",
        "    ,callbacks=[model_weights_checkpoint, early_stopping, json_logging_callback, optimizer_weights_callback]\n",
        "    )   \n",
        "    end = time()\n",
        "    duration = round(end-start,2)\n",
        "    write_line_to_file('Training Duration: '+str(duration)+' Seconds', log_dir)\n",
        "elif experiment_phase == 'training':\n",
        "    start = time()\n",
        "    history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(x_dev, y_dev)\n",
        "    ,callbacks=[model_weights_checkpoint, early_stopping, json_logging_callback, optimizer_weights_callback]\n",
        "    )   \n",
        "    end = time()\n",
        "    duration = round(end-start,2)\n",
        "    write_line_to_file('Training Duration: '+str(duration)+' Seconds', log_dir)\n",
        "elif experiment_phase == 'querying':\n",
        "    model.load_weights(project_path+folder_path+'weights.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6363/6363 [==============================] - 78s 12ms/step - loss: 0.5451 - cosine_sim: 0.4549 - val_loss: 0.6208 - val_cosine_sim: 0.3792\n",
            "Epoch 2/50\n",
            "6363/6363 [==============================] - 77s 12ms/step - loss: 0.5237 - cosine_sim: 0.4763 - val_loss: 0.6148 - val_cosine_sim: 0.3852\n",
            "Epoch 3/50\n",
            "6363/6363 [==============================] - 76s 12ms/step - loss: 0.5099 - cosine_sim: 0.4901 - val_loss: 0.6146 - val_cosine_sim: 0.3854\n",
            "Epoch 4/50\n",
            "6363/6363 [==============================] - 76s 12ms/step - loss: 0.4962 - cosine_sim: 0.5038 - val_loss: 0.6127 - val_cosine_sim: 0.3873\n",
            "Epoch 5/50\n",
            "6363/6363 [==============================] - 75s 12ms/step - loss: 0.4825 - cosine_sim: 0.5175 - val_loss: 0.6148 - val_cosine_sim: 0.3852\n",
            "Epoch 6/50\n",
            "6363/6363 [==============================] - 76s 12ms/step - loss: 0.4690 - cosine_sim: 0.5310 - val_loss: 0.6149 - val_cosine_sim: 0.3851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvCSOfTFPRWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.optimizer.set_weights(weight_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6Jx4uwK67RB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6e3ef46-48cc-4f67-945c-b5134bc82da4"
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    x_test = array([item['array'] for item in test])\n",
        "    y_test = array([comparison_matrix[h2id[item['word']]] if item['word'] in h2id else output_vec_model[item['word']] for item in test])\n",
        "    test_eval = model.evaluate(x_test, y_test)\n",
        "    test_loss = test_eval[0]\n",
        "    test_cosim = test_eval[1]\n",
        "    log_str = 'Test Loss: '+str(test_loss)+' - '+'Cosine Similarity: ' + str(test_cosim)\n",
        "    write_line_to_file(log_str, log_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "252/252 [==============================] - 1s 5ms/step - loss: 0.6142 - cosine_sim: 0.3858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt0qyeJDha_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d06166b1-c176-406b-c0ba-b38dba0e0164"
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    plt.plot(history.history['cosine_sim'])\n",
        "    plt.plot(history.history['val_cosine_sim'])\n",
        "    plt.title('Training History')\n",
        "    plt.ylabel('Cosine Similarity')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['training', 'development'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTtfuWPQaXQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "953321ae-9232-4b47-c52b-ecf696b00e94"
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Training History')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['training', 'development'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1NVpDTFX4MC",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating the model based on its performance on the testing set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Fn6N-nWDOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec_sim_coefficient = 0.6\n",
        "intent_coefficient = 0.4\n",
        "intent_threshold = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsRLw2x3USM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(inputs, topn, max_seq_len, models, tools):\n",
        "    globals().update(models)\n",
        "    words = inputs['words'] if 'words' in inputs else ['UNK' for definition in inputs['definitions']]\n",
        "    definitions = inputs['definitions']\n",
        "    general_tags= inputs['general_tags'] if 'general_tags' in inputs else [set() for definition in inputs['definitions']]\n",
        "    sense_tags= inputs['sense_tags'] if 'sense_tags' in inputs else [set() for definition in inputs['definitions']]\n",
        "    sources = inputs['sources'] if 'sources' in inputs else ['UNK' for definition in inputs['definitions']]\n",
        "    preprocessed_definitions = []\n",
        "    globals().update(tools)\n",
        "    \n",
        "    if 'intent_model' in globals():\n",
        "        intent_tools = {'intent_g2id':intent_g2id, 'id2c':intent_id2c, 'normalizer':normalizer,'intent_maxlen':intent_maxlen\n",
        "        ,'intent_model':intent_model, 'intent_threshold':intent_threshold}\n",
        "        intent_classes = query_intent_classifier(definitions, intent_tools, method='names')\n",
        "        intent_probs = query_intent_classifier(definitions, intent_tools, method='probs')\n",
        "    else:\n",
        "        intent_classes = [set() for i in range(len(definitions))]\n",
        "    \n",
        "    \n",
        "    samples = []\n",
        "    items = []\n",
        "    for (word, definition) in zip(words, definitions):\n",
        "        # making a sample out of the definition\n",
        "        original_definition, preprocessed_definition, nparray = preprocess_definition(definition, max_seq_len, tools)\n",
        "        preprocessed_definitions.append(preprocessed_definition)\n",
        "        sample = nparray.reshape((-1, max_seq_len))\n",
        "        samples.append(sample)\n",
        "    samples = array(samples)\n",
        "    samples = samples.reshape((-1, max_seq_len))\n",
        "    # running the models on the sample\n",
        "    preds = model.predict(samples)\n",
        "    if 'attention_model' in models:\n",
        "        weights = attention_model(samples) # batch_size*1*\n",
        "    else:\n",
        "        weights = array([array([1/max_seq_len for kprim in range(max_seq_len)]) for k in range(len(samples))])\n",
        "    # calculating the cosine distance between the output and each head word\n",
        "    dists = dist.cdist(preds, comparison_matrix, metric=\"cosine\")\n",
        "    sims = 1 - dists\n",
        "    del dists\n",
        "    sims = nan_to_num(sims)\n",
        "\n",
        "    # combine intent score -begin\n",
        "    if 'intent_model' in globals():\n",
        "        intent_c2id = {}\n",
        "        for (intent_i, intent_c) in intent_id2c.items():\n",
        "            intent_c2id[intent_c] = intent_i\n",
        "        for sample_idx, (s, p) in enumerate(zip(sims, intent_probs)):\n",
        "            for head_idx in range(len(s)):\n",
        "                head_word = id2h[head_idx]\n",
        "                head_word_pos_tags = word_tags[head_word] # a set\n",
        "                head_word_pos_ids = [intent_c2id[tag] for tag in head_word_pos_tags if tag in intent_c2id]\n",
        "                curr_intent_score = 0\n",
        "                for hwp_id in head_word_pos_ids:\n",
        "                    if p[hwp_id] >= intent_threshold:\n",
        "                        curr_intent_score += p[hwp_id] \n",
        "                sims[sample_idx][head_idx] = sims[sample_idx][head_idx] + min(intent_coefficient, intent_coefficient*curr_intent_score)\n",
        "    # combine intent score -end\n",
        "\n",
        "    candidate_ids = flip(sims.argsort(), 1)\n",
        "    del sims\n",
        "    \n",
        "    \n",
        "    \n",
        "    for (cid, weight, word, definition, preprocessed_definition, nparray, source, stags, gtags, intent_class) in zip(candidate_ids, weights, words, definitions, preprocessed_definitions, samples, sources, sense_tags, general_tags, intent_classes):\n",
        "        \n",
        "\n",
        "        # curr_def_is_a_word = False\n",
        "        # if definition.strip() in h2id:\n",
        "        #     curr_def_is_a_word = True\n",
        "        # if curr_def_is_a_word == True:\n",
        "        #     curr_def_id = h2id[definition.strip()]\n",
        "        #     cid = [curr_id for curr_id in cid if curr_def_id!=curr_id]\n",
        "        \n",
        "        # remove all definition words from cid -begin\n",
        "        definition_tokens = set(definition.split())\n",
        "        definition_tokens = set([dt for dt in definition_tokens if dt in h2id])\n",
        "        definition_tokens_ids = set([h2id[dt] for dt in definition_tokens])\n",
        "        cid = [curr_id for curr_id in cid if curr_id not in definition_tokens_ids]\n",
        "        # remove all definition words from cid -end\n",
        "        \n",
        "        \n",
        "        cid = list(cid)\n",
        "        # getting the top words from the ranking\n",
        "        topwords = [id2h[idx] for idx in cid[:topn]]\n",
        "        # calculating the ranks\n",
        "        num_words = len(h2id)\n",
        "        accepted_output_words = synonyms[word] if word in synonyms else set()\n",
        "        accepted_output_words.add(word)\n",
        "        try:\n",
        "            main_word_rank = cid.index(h2id[word])+1\n",
        "        except:\n",
        "            main_word_rank = num_words\n",
        "        accepted_output_ids = [h2id[w] for w in accepted_output_words if w in h2id and w!=original_definition.strip()]\n",
        "        try:\n",
        "            output_word_id, given_word_rank = get_rank(cid, accepted_output_ids)\n",
        "        except:\n",
        "            given_word_rank = num_words\n",
        "            output_word_id = False\n",
        "        # making the report item\n",
        "        item = {\n",
        "            'main_word':word,\n",
        "            'original_definition':definition,\n",
        "            'preprocessed_definition':preprocessed_definition,\n",
        "            'array':nparray,\n",
        "            'attention':weight,\n",
        "            'intent':set(intent_class),\n",
        "            'main_word_rank':main_word_rank,\n",
        "            'synset_word_rank':given_word_rank,\n",
        "            'synset_word':'UNK' if not output_word_id else id2h[output_word_id],\n",
        "            'topwords':topwords,\n",
        "            'source':source,\n",
        "            'sense_tags':stags,\n",
        "            'general_tags':gtags\n",
        "        }\n",
        "        items.append(item)\n",
        "    return items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwMqLVpTaday",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stratified_sample(items, sources, num_head_words, sample_size):\n",
        "    items = [item for item in items if item['source'] in sources]\n",
        "    num_items = num_head_words\n",
        "    section_size = int(num_items/sample_size)\n",
        "    sections = [[] for i in range(sample_size)]\n",
        "    for i in range(sample_size):\n",
        "        sections[i] = [item for item in items if section_size*i<=item['rank']<=section_size*(i+1)]\n",
        "    samples = [sample(sections[i], 1)[0] if len(sections[i])>0 else sample(sections[i-1]+sections[i+1],1)[0] for i in range(sample_size)]\n",
        "    return samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uagVHoMKs49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    train_samples = stratified_sample(train, {'amid','moeen-vy','dehkhoda-vy'}, num_head_words, 500)\n",
        "    train_inputs = {\n",
        "        'definitions':[item['original_definition'] for item in train_samples],\n",
        "        'words':[item['word'] for item in train_samples],\n",
        "        'sources':[item['source'] for item in train_samples],\n",
        "        'sense_tags':[item['sense_tags'] for item in train_samples],\n",
        "        'general_tags':[item['general_tags'] for item in train_samples]\n",
        "    }\n",
        "    if 'attention_model' in globals():\n",
        "        q = query(train_inputs, 10, max_seq_len, {'model':model, 'attention_model':attention_model}, tools)\n",
        "    else:\n",
        "        q = query(train_inputs, 10, max_seq_len, {'model':model}, tools)\n",
        "    if use_intent_classifier == True:\n",
        "        write_line_to_file('-------------', log_dir)\n",
        "        intent_eval = evaluate_intent_classifier(q, word_tags)\n",
        "        write_line_to_file('Intent Classifier Seen Evaluation: ', log_dir)\n",
        "        write_line_to_file(str(intent_eval), log_dir)\n",
        "    e = evaluate(q)\n",
        "    write_line_to_file('-------------', log_dir)\n",
        "    log_str = 'Seen Evaluation:\\n'+'Median: '+str(e['main_eval']['median'])+', Variance: '+str(e['main_eval']['variance'])+', Acc@10: '+str(e['main_eval']['acc@10'])+', Acc@100: '+str(e['main_eval']['acc@100'])+'\\n'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    log_str = 'Seen Synonym Evaluation:\\n'+'Median: '+str(e['synset_eval']['median'])+', Variance: '+str(e['synset_eval']['variance'])+', Acc@10: '+str(e['synset_eval']['acc@10'])+', Acc@100: '+str(e['synset_eval']['acc@100'])+'\\n'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    write_line_to_file(str(e['bad_results']), log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkFrpE5Vzm7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    test_samples = stratified_sample(test, {'amid','moeen-vy','dehkhoda-vy'}, num_head_words, test_sample_size)\n",
        "    test_inputs = {\n",
        "        'definitions':[item['original_definition'] for item in test_samples],\n",
        "        'words':[item['word'] for item in test_samples],\n",
        "        'sources':[item['source'] for item in test_samples],\n",
        "        'sense_tags':[item['sense_tags'] for item in test_samples],\n",
        "        'general_tags':[item['general_tags'] for item in test_samples]\n",
        "    }\n",
        "    if 'attention_model' in globals():\n",
        "        q = query(test_inputs, 10, max_seq_len, {'model':model, 'attention_model':attention_model}, tools)\n",
        "    else:\n",
        "        q = query(test_inputs, 10, max_seq_len, {'model':model}, tools)\n",
        "    if use_intent_classifier == True:\n",
        "        write_line_to_file('-------------', log_dir)\n",
        "        intent_eval = evaluate_intent_classifier(q, word_tags)\n",
        "        write_line_to_file('Intent Classifier Unseen Evaluation: ', log_dir)\n",
        "        write_line_to_file(str(intent_eval), log_dir)\n",
        "    e = evaluate(q)\n",
        "    write_line_to_file('-------------', log_dir)\n",
        "    log_str = 'Unseen Evaluation:\\n'+'Median: '+str(e['main_eval']['median'])+', Variance: '+str(e['main_eval']['variance'])+', Acc@10: '+str(e['main_eval']['acc@10'])+', Acc@100: '+str(e['main_eval']['acc@100'])+'\\n'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    log_str = 'Unseen Synonym Evaluation:\\n'+'Median: '+str(e['synset_eval']['median'])+', Variance: '+str(e['synset_eval']['variance'])+', Acc@10: '+str(e['synset_eval']['acc@10'])+', Acc@100: '+str(e['synset_eval']['acc@100'])+'\\n'\n",
        "    write_line_to_file(log_str, log_dir)\n",
        "    write_line_to_file(str(e['bad_results']), log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9TwgJ7hFYIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    synset_good10 = [item for item in q if 1<=item['synset_word_rank']<=10]\n",
        "    synset_good100 = [item for item in q if 10<item['synset_word_rank']<=100]\n",
        "    synset_bad100 = [item for item in q if 100<item['synset_word_rank']]\n",
        "    save_group_reports(synset_good10, project_path+folder_path+'good10.html')\n",
        "    save_group_reports(synset_good100, project_path+folder_path+'good100.html')\n",
        "    save_group_reports(synset_bad100, project_path+folder_path+'bad100.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA2Ixg6vevvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if experiment_phase in {'training','continue'}:\n",
        "    dictionaries = {'amid','moeen-vy','dehkhoda-vy'}\n",
        "    for dictionary in dictionaries:\n",
        "        test_samples = stratified_sample(test, {dictionary}, num_head_words, test_sample_size)\n",
        "        test_inputs = {\n",
        "            'definitions':[item['original_definition'] for item in test_samples],\n",
        "            'words':[item['word'] for item in test_samples],\n",
        "            'sources':[item['source'] for item in test_samples]\n",
        "        }\n",
        "        if 'attention_model' in globals():\n",
        "            q = query(test_inputs, 10, max_seq_len, {'model':model, 'attention_model':attention_model}, tools)\n",
        "        else:\n",
        "            q = query(test_inputs, 10, max_seq_len, {'model':model}, tools)\n",
        "        e = evaluate(q)\n",
        "        write_line_to_file('-------------', log_dir)\n",
        "        log_str = 'Source: '+dictionary\n",
        "        write_line_to_file(log_str, log_dir)\n",
        "        log_str = 'Unseen Evaluation:\\n'+'Median: '+str(e['main_eval']['median'])+', Variance: '+str(e['main_eval']['variance'])+', Acc@10: '+str(e['main_eval']['acc@10'])+', Acc@100: '+str(e['main_eval']['acc@100'])+'\\n'\n",
        "        write_line_to_file(log_str, log_dir)\n",
        "        log_str = 'Unseen Synonym Evaluation:\\n'+'Median: '+str(e['synset_eval']['median'])+', Variance: '+str(e['synset_eval']['variance'])+', Acc@10: '+str(e['synset_eval']['acc@10'])+', Acc@100: '+str(e['synset_eval']['acc@100'])+'\\n'\n",
        "        write_line_to_file(log_str, log_dir)\n",
        "        write_line_to_file(str(e['bad_results']), log_dir)\n",
        "        correct_words = [item['main_word'] for item in q]\n",
        "        input_descriptions = [item['original_definition'] for item in q]\n",
        "        dict_evaluation_df = pd.DataFrame(list(zip(correct_words, input_descriptions)), columns=['word','description'])\n",
        "        dict_evaluation_df.to_excel(project_path+folder_path+dictionary+'.xlsx', encoding='utf-8')\n",
        "        for k in range(3):\n",
        "            output_words = [item['topwords'][k] for item in q]\n",
        "            evaluation_df = pd.DataFrame(list(zip(output_words, input_descriptions)), columns=['word','description'])\n",
        "            evaluation_df.to_excel(project_path+folder_path+dictionary+'-'+str(k+1)+'.xlsx', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_w7rs5WMu3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "definition = '   '\n",
        "inputs = {'definitions': [definition,\n",
        "'',\n",
        "' ']}\n",
        "models = {'model':model}\n",
        "if 'attention_model' in globals():\n",
        "    models['attention_model'] = attention_model\n",
        "query(inputs, 10, max_seq_len, models, tools)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}